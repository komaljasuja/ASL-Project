This repository will allow one to display ASL through an camera and have it be recognized by the computer. It will then be stored and converted into text. The user will have the option of having it be said aloud, converted to a different language or both

Motivation / Why we have created this: The motivation behind this project is to create new pathways and forms of communcation for those who are deaf and others.

Libraries dependencies
The libraries nescessary for this are numpy, math, cv2, traceback, pyttsx3, load_model, HandDetector, string, pyenchant, tkinter, googletrans, pickle, 

How to use and run
To use and run the program, the data first will be trained and then tested in the use of prediction and identification of sign language symbols.

Images or design 
  started with ASL
  Translate to other language as other may not know english   - Eg : translate.py -> this file is responsible for translation 
  Predict the word to save and fasten the communication
  Converting text to Speech


some images from internet for all ASL symbols

all credit to the dataset 
  sources of data set 
  
videos help

You can mention what is our future plan or challenges that you have thought of
  1.  All the ASL are considering they are using there right hand - what if they use / comformatable in left hand - then these dastaset will not be useful
  2.  Present implementation is using laptop - need to implement the same on Raspberry Pi or ESP 32 using ESP 32 cam module
  3.  
